date       <- c();
i <- 1;
for( iFile in list.files( paste( projPath, "/data/InauguralSpeeches", sep = "") ) ){
#iFile <- list.files( paste( projPath, "/data/InauguralSpeeches", sep = "") )[21]
# store president's name
aux <- strsplit( x = iFile, split = "inaug" )
aux <- strsplit( x = aux[[1]][2], split = "-" )
presidents[ i ] <- aux[[1]][1]
# store term information
term[ i ] <- strsplit( x = aux[[1]][length(aux[[1]])], split = ".txt" )
# conditionals deal with special name differences between files
if( presidents[ i ] == "GroverCleveland" ){
# store party information
party[ i ] <- "Democratic"
# store date information
if( iFile == "inaugGroverCleveland-I-1.txt" ){
date <- "3/4/1885"
} else {
date <- "3/4/1893"
}
} else if( presidents[ i ] == "JamesGarfield" ) {
party[ i ] <- "Republican"
date       <- "3/4/1881"
} else if( presidents[ i ] == "JamesKPolk" ) {
party[ i ] <- "Democratic"
date       <- "3/4/1845"
} else if( presidents[ i ] == "MartinvanBuren" ) {
party[ i ] <- "Democratic"
date       <- "3/4/1837"
} else if( presidents[ i ] == "RichardNixon" ) {
party[ i ] <- "Republican"
if( iFile == "inaugRichardNixon-1.txt" ){
date       <- "1/20/1969"
} else {
date       <- "1/20/1973"
}
} else {
# store party information
party[ i ] <- inaugInfo[ File == presidents[i] ]$Party[ 1 ]
# store date information
nameLong <- inaugInfo[ File == presidents[i] ]$President[1]
date     <- inaugDate[ which( inaugDate[,1] == nameLong ), 1 + as.numeric(term[[i]]) ]
}
# read speech
speech <- readtext( paste( paste( projPath, "/data/InauguralSpeeches", sep = ""),
iFile, sep = "/") );
# put speech in tidy format
speech <- speech %>%
unnest_tokens(word, text);
# remove stop words from speech
speech <- speech %>%
anti_join( stop_words[ stop_words$lexicon == "snowball", ] )
# create dataframe
speechesList[[ i ]] <- data.frame( "doc_id" = speech$doc_id,
"president" = rep( presidents[i], nrow(speech) ) ,
"term" = rep( term[[i]][1], nrow(speech) ),
"date" = rep( date, nrow(speech) ),
"party" = rep( party[i], nrow(speech) ),
"word" = speech$word );
i <- i + 1;
}
# Now, merge all speeches into a datatable
speechesDt <- as.data.table( speechesList[[1]] );
for( i in 2:length(speechesList) ){
speechesDt <- rbind( speechesDt, speechesList[[ i ]] );
}
countRepublican <- speechesDt[ party == "Republican" ] %>% count(word, sort = TRUE);
countDemocrat   <- speechesDt[ party == "Democratic" ] %>% count(word, sort = TRUE);
speechesDt$word <- as.character( speechesDt$word )
speechesDt %>%
filter( party == "Republican" ) %>%
inner_join( get_sentiments("bing") ) %>%
count( word, sentiment, sort = TRUE ) %>%
acast( word ~ sentiment, fill = 0 ) %>%
comparison.cloud(colors = c("#F8766D", "#00BFC4"),
max.words = 100)
speechesDt %>%
filter( party == "Democratic" ) %>%
inner_join( get_sentiments("bing") ) %>%
count( word, sentiment, sort = TRUE ) %>%
acast( word ~ sentiment, fill = 0 ) %>%
comparison.cloud(colors = c("#F8766D", "#00BFC4"),
max.words = 100)
# load stop words table
data( stop_words );
# data path
projPath <- "/Users/pedrohmariani/Documents/Columbia/Academic/Fall 2017/AppliedDataScience/Projects/proj1"
# read inauguration info
#inaugInfo <- read_excel(".data/InaugurationInfo.xlsx", sheet = 1)
inaugInfo <- as.data.table( read_excel(paste( projPath, "/data/InaugurationInfo.xlsx", sep = ""), sheet = 1) )
#inaugInfo <- read.csv(paste( projPath, "/data/InaugurationInfo copy.csv", sep = ""), header = TRUE ) # temporario
#inaugInfo <- lapply( inaugInfo[[1]], as.character );
#inaugInfo <- lapply( inaugInfo, function(x) strsplit( x , ";" ) );
# read inauguration date
dateFile <-  readtext( paste( projPath, "/data/InauguationDates.txt", sep = "") )
dateFile  <- strsplit( x = dateFile$text, split = "\n")
dateFile  <- sapply( dateFile[[1]][2:47], function(x) strsplit( x, split = "\t" ) )
inaugDate <- c(dateFile[[2]],"")
for( i in 3:46 ){
if( length( dateFile[[i]] ) == 4 ){
inaugDate <- rbind( inaugDate, c( dateFile[[i]], "" ) )
} else{
inaugDate <- rbind( inaugDate, dateFile[[i]] )
}
}
colnames( inaugDate ) <- dateFile[[1]]
View(inaugDate)
# initialize variables
speechesList <- list();
counts     <- list();
presidents <- c();
term       <- c();
party      <- c();
date       <- c();
i <- 1;
for( iFile in list.files( paste( projPath, "/data/InauguralSpeeches", sep = "") ) ){
#iFile <- list.files( paste( projPath, "/data/InauguralSpeeches", sep = "") )[21]
# store president's name
aux <- strsplit( x = iFile, split = "inaug" )
aux <- strsplit( x = aux[[1]][2], split = "-" )
presidents[ i ] <- aux[[1]][1]
# store term information
term[ i ] <- strsplit( x = aux[[1]][length(aux[[1]])], split = ".txt" )
# conditionals deal with special name differences between files
if( presidents[ i ] == "GroverCleveland" ){
# store party information
party[ i ] <- "Democratic"
# store date information
if( iFile == "inaugGroverCleveland-I-1.txt" ){
date <- "3/4/1885"
} else {
date <- "3/4/1893"
}
} else if( presidents[ i ] == "JamesGarfield" ) {
party[ i ] <- "Republican"
date       <- "3/4/1881"
} else if( presidents[ i ] == "JamesKPolk" ) {
party[ i ] <- "Democratic"
date       <- "3/4/1845"
} else if( presidents[ i ] == "MartinvanBuren" ) {
party[ i ] <- "Democratic"
date       <- "3/4/1837"
} else if( presidents[ i ] == "RichardNixon" ) {
party[ i ] <- "Republican"
if( iFile == "inaugRichardNixon-1.txt" ){
date       <- "1/20/1969"
} else {
date       <- "1/20/1973"
}
} else {
# store party information
party[ i ] <- inaugInfo[ File == presidents[i] ]$Party[ 1 ]
# store date information
nameLong <- inaugInfo[ File == presidents[i] ]$President[1]
date     <- inaugDate[ which( inaugDate[,1] == nameLong ), 1 + as.numeric(term[[i]]) ]
}
# read speech
speech <- readtext( paste( paste( projPath, "/data/InauguralSpeeches", sep = ""),
iFile, sep = "/") );
# put speech in tidy format
speech <- speech %>%
unnest_tokens(word, text);
# remove stop words from speech
speech <- speech %>%
anti_join( stop_words[ stop_words$lexicon == "snowball", ] )
# create dataframe
speechesList[[ i ]] <- data.frame( "doc_id" = speech$doc_id,
"president" = rep( presidents[i], nrow(speech) ) ,
"term" = rep( term[[i]][1], nrow(speech) ),
"date" = rep( date, nrow(speech) ),
"party" = rep( party[i], nrow(speech) ),
"word" = speech$word );
i <- i + 1;
}
# Now, merge all speeches into a datatable
speechesDt <- as.data.table( speechesList[[1]] );
for( i in 2:length(speechesList) ){
speechesDt <- rbind( speechesDt, speechesList[[ i ]] );
}
# convert word from factor to character vector
speechesDt$word <- as.character( speechesDt$word )
speechesDt$date <- as.character( speechesDt$date )
speechesDt$date <- as.Date(speechesDt$date, "%m/%d/%Y")
speechesDt$date
afinn <- speechDt %>%
inner_join(get_sentiments("afinn"))
afinn <- speechesDt %>%
inner_join(get_sentiments("afinn"))
View(afinn)
afinn <- speechesDt %>%
inner_join( get_sentiments("afinn") ) %>%
group_by( date ) %>%
summarise( sentiment = sum(score) ) %>%
mutate(method = "AFINN")
View(afinn)
speechesDt %>%
inner_join( get_sentiments("afinn") ) %>%
group_by( date ) %>%
summarise( sentiment = sum(score) ) %>%
ggplot( aes(Date, Views)) +
geom_line() +
scale_x_date(format = "%b-%Y") + xlab("")
speechesDt %>%
inner_join( get_sentiments("afinn") ) %>%
group_by( date ) %>%
summarise( sentiment = sum(score) ) %>%
ggplot( aes(Date, Views)) +
geom_line() +
scale_x_date()
speechesDt %>%
inner_join( get_sentiments("afinn") ) %>%
group_by( date ) %>%
summarise( sentiment = sum(score) ) %>%
ggplot( aes(date, sentiment) ) +
geom_line() +
scale_x_date()
speechesDt %>%
inner_join( get_sentiments("afinn") ) %>%
group_by( date ) %>%
summarise( sentiment = sum(score) ) %>%
ggplot( aes(date, sentiment) ) +
geom_bar(stat = "identity") +
scale_x_date()
speechesDt %>%
inner_join( get_sentiments("afinn") ) %>%
group_by( date ) %>%
summarise( sentiment = sum(score) ) %>%
ggplot( aes(date, sentiment) ) +
geom_bar(stat = "identity") +
scale_x_date() +
ggtitle("Sentiment over time") +
theme(plot.title = element_text(lineheight = .8, face = "bold"))
speechesDt %>%
inner_join( get_sentiments("afinn") ) %>%
group_by( date ) %>%
summarise( sentiment = sum(score) ) %>%
ggplot( aes(date, sentiment) ) +
geom_bar(stat = "identity", width = 2) +
scale_x_date() +
ggtitle("Sentiment over time") +
theme(plot.title = element_text(lineheight = .8, face = "bold"))
speechesDt %>%
inner_join( get_sentiments("afinn") ) %>%
group_by( date ) %>%
summarise( sentiment = sum(score) ) %>%
ggplot( aes(date, sentiment) ) +
geom_bar(stat = "identity", width = .2) +
scale_x_date() +
ggtitle("Sentiment over time") +
theme(plot.title = element_text(lineheight = .8, face = "bold"))
speechesDt %>%
inner_join( get_sentiments("afinn") ) %>%
group_by( date ) %>%
summarise( sentiment = sum(score) ) %>%
ggplot( aes(date, sentiment) ) +
geom_bar(stat = "identity", width = 20) +
scale_x_date() +
ggtitle("Sentiment over time") +
theme(plot.title = element_text(lineheight = .8, face = "bold"))
speechesDt %>%
inner_join( get_sentiments("afinn") ) %>%
group_by( date ) %>%
summarise( sentiment = sum(score) ) %>%
ggplot( aes(date, sentiment) ) +
geom_bar(stat = "identity" ) +
scale_x_date() +
ggtitle("Sentiment over time") +
theme(plot.title = element_text(lineheight = .8, face = "bold"))
speechesDt %>%
inner_join( get_sentiments("afinn") ) %>%
group_by( date ) %>%
summarise( sentiment = sum(score) ) %>%
ggplot( aes(date, sentiment) ) +
geom_bar(stat = "identity" ) +
geom_line() +
scale_x_date() +
ggtitle("Sentiment over time") +
theme(plot.title = element_text(lineheight = .8, face = "bold"))
speechesDt %>%
inner_join( get_sentiments("afinn") ) %>%
group_by( date ) %>%
summarise( sentiment = sum(score) ) %>%
ggplot( aes(date, sentiment) ) +
geom_bar(stat = "identity" ) +
geom_line() +
scale_x_date( date_breaks = "20 years") +
ggtitle("Sentiment over time") +
theme(plot.title = element_text(lineheight = .8, face = "bold"))
speechesDt %>%
inner_join( get_sentiments("afinn") ) %>%
group_by( date ) %>%
summarise( sentiment = sum(score) ) %>%
ggplot( aes(date, sentiment) ) +
geom_bar(stat = "identity" ) +
geom_line() +
scale_x_date( ) +
ggtitle("Sentiment over time") +
theme(plot.title = element_text(lineheight = .8, face = "bold"))
speechesDt %>%
inner_join( get_sentiments("afinn") ) %>%
group_by( date ) %>%
summarise( sentiment = sum(score) ) %>%
ggplot( aes(date, sentiment) ) +
geom_bar(stat = "identity", width = 1 ) +
geom_line() +
scale_x_date( ) +
ggtitle("Sentiment over time") +
theme(plot.title = element_text(lineheight = .8, face = "bold"))
shiny::runApp('Documents/PSR/Synthetics Series Validation/Shiny/v1')
shiny::runApp('Documents/PSR/Synthetics Series Validation/Shiny/v1')
shiny::runApp('Documents/PSR/Synthetics Series Validation/Shiny/v1')
}
}
---
1.25^2-(-.75)^2
1.25^2-(-.75)^2
1.25^2
.75^2
1.25
1/1.25
version
install.packages("EBImage")
library("EBImage")
library(data.table)
install.packages("data.table")
library(data.table)
library(shiny)
install.packages("shiny")
install.packages("ggplot2")
install.packages("EBImage")
library(EBImage)
install.packages("EBImage")
install.packages("EBImage")
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
library("EBImage")
n_dig = 0
n_pixel_row = 20
n_pixel_col = 20
export = T
dat_train   <- fread("/Users/pedrohmariani/Documents/Columbia/Academic/Fall 2017/AppliedDataScience/Projects/TZstatsFolder/Fall2017-project3-fall2017-project3-grp1/data/training_set/sift_train.csv",
sep = ",")
library("gbm")
library(data.table)
### Train with gradient boosting model
if(is.null(par)){
depth <- 3
} else {
depth <- par$depth
}
par=NULL
### Train with gradient boosting model
if(is.null(par)){
depth <- 3
} else {
depth <- par$depth
}
dat_train   <- fread("/Users/pedrohmariani/Documents/Columbia/Academic/Fall 2017/AppliedDataScience/Projects/TZstatsFolder/Fall2017-project3-fall2017-project3-grp1/data/training_set/sift_train.csv",
sep = ",")
label_train <- read.csv("/Users/pedrohmariani/Documents/Columbia/Academic/Fall 2017/AppliedDataScience/Projects/TZstatsFolder/Fall2017-project3-fall2017-project3-grp1/data/training_set/label_train.csv")
fit_gbm <- gbm.fit(x=dat_train[,2:ncol(dat_train)], y=label_train[,2],
n.trees = 20,
distribution="multinomial",
interaction.depth=depth,
bag.fraction = 0.5,
verbose=FALSE)
tm(fit_gbm)
rm(fit_gbm)
fit_gbm <- gbm.fit(x=dat_train[,2:ncol(dat_train)], y=label_train[,2],
n.trees = 50,
distribution="multinomial",
interaction.depth=depth,
bag.fraction = 0.5,
verbose=FALSE)
best_iter <- gbm.perf(fit_gbm, method="OOB", plot.it = FALSE)
best_iter
View(fit_gbm$fit)
run.lda
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
## OBS - add more packages here
if(!require("gbm")){
install.packages("gbm")
}
## OBS - add more packages here
library("EBImage")
library("gbm")
library("MASS")
library("OpenImageR")
library("jpeg")
setwd("/Users/pedrohmariani/Documents/Columbia/Academic/Fall 2017/AppliedDataScience/Projects/TZstatsFolder/Fall2017-project3-fall2017-project3-grp1/doc")
experiment_dir <- "../data/training_set/" # This will be modified for different data sets.
img_train_dir <- paste(experiment_dir, "train/", sep="")
img_test_dir <- paste(experiment_dir, "test/", sep="")
run.cv = T # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train = TRUE # process features for training set
run.test = TRUE # run evaluation on an independent test set
run.feature.test = TRUE # process features for test set
# Boolean variables for Feature Extraction
run.pca = FALSE #Performs PCA dimensionality reduction on images
run.hogs = FALSE
run.cnn = FALSE
run.lbp = FALSE
# Boolean variables for running model
run.gbm = FALSE
run.svm = FALSE
run.rf = FALSE
run.lda = TRUE
model_values<-seq(0.01,0.25,0.05) #for GBM
#model_labels = paste("GBM with shrinkage value =", model_values) # for GBM
svm_gamma_values <- seq(0, 0.5, by = 0.1)
svm_gamma_labels = paste("SVM gamma =", svm_gamma_values) # for SVM
rf_par = expand.grid(mtry = seq(5,15),ntree = seq(1000,2500,500)) #for RF
label_train <- read.csv("../data/training_set/label_train.csv", header=T)
source("../lib/feature - final.R")
source("../lib/train - final.R")
source("../lib/test - final.R")
load("../output/feature_train.RData")
load("../output/feature_test.RData")
source("../lib/cross_validation.R")
baseline_dat_train <- read.csv("../data/training_set/sift_train.csv", header=T)
baseline_dat_train<-baseline_dat_train[,-1]
dat_train <- baseline_dat_train
if( run.lda ){
#tm_train_lda <- system.time(model.lda <- train( dat_train, label_train, run.lda = TRUE ))
tm_train_lda <- system.time( model.lda <- lda( dat_train, label_train[,2], CV = T ) )
save(model.lda, file="../output/model_lda.RData")
}
dat_train
if(!require("EBImage")){
source("https://bioconductor.org/biocLite.R")
biocLite("EBImage")
}
## OBS - add more packages here
if(!require("gbm")){
install.packages("gbm")
}
## OBS - add more packages here
library("EBImage")
library("gbm")
library("MASS")
library("OpenImageR")
library("jpeg")
setwd("/Users/pedrohmariani/Documents/Columbia/Academic/Fall 2017/AppliedDataScience/Projects/TZstatsFolder/Fall2017-project3-fall2017-project3-grp1/doc")
experiment_dir <- "../data/training_set/" # This will be modified for different data sets.
img_train_dir <- paste(experiment_dir, "train/", sep="")
img_test_dir <- paste(experiment_dir, "test/", sep="")
run.cv = T # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train = TRUE # process features for training set
run.test = TRUE # run evaluation on an independent test set
run.feature.test = TRUE # process features for test set
# Boolean variables for Feature Extraction
run.pca = FALSE #Performs PCA dimensionality reduction on images
run.hogs = FALSE
run.cnn = FALSE
run.lbp = FALSE
# Boolean variables for running model
run.gbm = FALSE
run.svm = TRUE
run.rf = FALSE
run.lda = FALSE
model_values<-seq(0.01,0.25,0.05) #for GBM
svm_gamma_values <- seq(0, 0.5, by = 0.1)
svm_gamma_labels = paste("SVM gamma =", svm_gamma_values) # for SVM
label_train <- read.csv("../data/training_set/label_train.csv", header=T)
source("../lib/feature - final.R")
source("../lib/train - final.R")
source("../lib/test - final.R")
load("../output/feature_train.RData")
load("../output/feature_test.RData")
source("../lib/cross_validation.R")
baseline_dat_train <- read.csv("../data/training_set/sift_train.csv", header=T)
baseline_dat_train<-baseline_dat_train[,-1]
dat_train <- baseline_dat_train
cv.svm = T
cv.gbm = F
cv.rf = F
cv.lda = F
cv.svm
cv.gbm
cv.rf
if(run.cv) {
if( cv.gbm ){
err_cv <- array(dim=c(length(model_values), 2))
for(k in 1:length(model_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function( as.data.frame(dat_train), label_train, model_values[k], K, cv.gbm = T)
#err_cv[k,]<-cv.function(baseline_dat_train,label_train,model_values[k],K,cv.gbm = T)
}
}
if( cv.svm ){
err_cv <- array(dim=c(length(svm_gamma_values), 2))
for(k in 1:length(svm_gamma_values)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function( dat_train, label_train, d = svm_gamma_values[k], K = K, cv.svm = T)
}
}
if( cv.rf ){
err_cv <- array(dim=c(nrow(rf_par), 2))
model_values = rf_par
for(k in 1:nrow(rf_par)){
cat("k=", k, "\n")
err_cv[k,] <- cv.function( dat_train, label_train, rf_par[k,], K, cv.rf = T)
}
}
save(err_cv, file="../output/err_cv.RData")
}
err_cv
